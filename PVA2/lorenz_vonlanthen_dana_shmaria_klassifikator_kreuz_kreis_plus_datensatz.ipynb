{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nachbearbeitung PVA2 - Klassifikator für den Kreuz-Kreis-Plus Datensatz\n",
    "In dieser Nachbearbeitung wird ein Klassifikator für den Kreuz-Kreis-Plus Datensatz erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kreation eines Decision-Tree Klassifikators mit den eigenen Daten\n",
    "\n",
    "Die Daten werden preprocesst, um sie in die Form zu bringen, in welcher sie mit einem Klassifikator verwendet werden können. Danach wird ein Decision-Tree-Klassifikator mit Zweidrittel der Daten trainiert und mit dem restlichen Drittel getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/output-lorenz.vonlanthen-dana.shmaria.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#-0-lorenz.vonlanthen-dana.shmaria.png</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>1.6</th>\n",
       "      <th>1.7</th>\n",
       "      <th>1.8</th>\n",
       "      <th>...</th>\n",
       "      <th>1.56</th>\n",
       "      <th>1.57</th>\n",
       "      <th>0.34</th>\n",
       "      <th>1.58</th>\n",
       "      <th>1.59</th>\n",
       "      <th>1.60</th>\n",
       "      <th>1.61</th>\n",
       "      <th>1.62</th>\n",
       "      <th>1.63</th>\n",
       "      <th>1.64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#-1-lorenz.vonlanthen-dana.shmaria.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#-2-lorenz.vonlanthen-dana.shmaria.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#-3-lorenz.vonlanthen-dana.shmaria.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#-4-lorenz.vonlanthen-dana.shmaria.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#-5-lorenz.vonlanthen-dana.shmaria.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   #-0-lorenz.vonlanthen-dana.shmaria.png  1  1.1  1.2  1.3  1.4  1.5  1.6  \\\n",
       "0  #-1-lorenz.vonlanthen-dana.shmaria.png  1    1    1    1    1    1    1   \n",
       "1  #-2-lorenz.vonlanthen-dana.shmaria.png  1    1    1    1    1    1    1   \n",
       "2  #-3-lorenz.vonlanthen-dana.shmaria.png  1    1    0    1    1    1    1   \n",
       "3  #-4-lorenz.vonlanthen-dana.shmaria.png  1    1    1    1    1    1    1   \n",
       "4  #-5-lorenz.vonlanthen-dana.shmaria.png  1    1    1    1    1    1    1   \n",
       "\n",
       "   1.7  1.8  ...  1.56  1.57  0.34  1.58  1.59  1.60  1.61  1.62  1.63  1.64  \n",
       "0    1    1  ...     1     1     1     0     1     1     1     1     1     1  \n",
       "1    1    1  ...     1     1     1     1     1     1     0     1     1     1  \n",
       "2    1    1  ...     1     1     0     1     1     0     1     1     1     1  \n",
       "3    1    1  ...     1     1     0     1     1     0     1     1     1     1  \n",
       "4    1    1  ...     1     1     1     0     1     1     0     1     1     1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SYMBOL_TO_INTEGER = {\n",
    "    '#': 0,\n",
    "    '+': 1,\n",
    "    'o': 2,\n",
    "    'x': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):    \n",
    "    df = data.drop(data.columns[0], axis=1)\n",
    "    classifier_features = df.to_numpy()\n",
    "\n",
    "    df = data[data.columns[0]].to_numpy()\n",
    "\n",
    "    vfunc = np.vectorize(lambda x: MAP_SYMBOL_TO_INTEGER[x[0][:1]])\n",
    "    classifier_labels = vfunc(df)\n",
    "    return classifier_features, classifier_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 0 1 3 2 0 2 2 2 1 0 1]\n",
      "[3 3 0 1 3 2 0 2 2 1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "X, y = preprocess_data(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(predictions)\n",
    "print(y_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Accuracy ist ziemlich gut und fast bei 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verwendung der kollaborativ gesammelten Daten\n",
    "Der zuvor gefittete Decision-Tree-Classifier wird für weitere Daten des kollaborativ gesammelten Datensatzes getestet. Dabei werden nur die Datensätze genommen, welche dieselbe Formattierung wie unser eigener Datensetz verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for root,dirs,files in os.walk(\"data\"):\n",
    "    for file in files:\n",
    "        if file.endswith('csv'):\n",
    "            test_data.append([file,pd.read_csv(\"data/\" + file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-daniel.zimmermann.csv\n",
      "[2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "0.3076923076923077\n",
      "\n",
      "\n",
      "output-nicolasMueller-matthiasFuhrimann-cedricAebi.csv\n",
      "[0 0 0 2 2 0 2 0 2 1 1 1 1 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "0.5897435897435898\n",
      "\n",
      "\n",
      "output-marco.hirsbrunner.csv\n",
      "[2 2 0 2 2 2 2 0 2 2 1 2 2 1 1 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "0.5384615384615384\n",
      "\n",
      "\n",
      "output-joel.boschung.csv\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "0.2564102564102564\n",
      "\n",
      "\n",
      "output-pascal.steiger.csv\n",
      "[2 2 2 2 0 2 2 2 2 1 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2\n",
      " 1 2]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "0.358974358974359\n",
      "\n",
      "\n",
      "output-jonas.augsburger.csv\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 2 3\n",
      " 3 3]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "0.20512820512820512\n",
      "\n",
      "\n",
      "output-hans-petzer.eggler.csv\n",
      "[2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2\n",
      " 2 1 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3]\n",
      "0.25\n",
      "\n",
      "\n",
      "output-lorenz.vonlanthen-dana.shmaria.csv\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3\n",
      " 3 3]\n",
      "0.9743589743589743\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_name, data in test_data:\n",
    "    print(file_name)\n",
    "    X, y = preprocess_data(data)\n",
    "    predictions = clf.predict(X)\n",
    "    print(predictions)\n",
    "    print(y)\n",
    "    print(accuracy_score(predictions, y))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nur für unseren eigenen Datensatz (siehe letzter Output) funktioniert der Classifier gut. Die anderen Daten/Zeichnungen sind zu unterschiedlich zu unseren. Deshalb wird im nächsten Teil ein Classifier mit Daten aus allen Datensätzen gefittet, um eine höhere allgemeine Accuracy zu erhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fitten des Classifiers aus allen Datensätzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "X_all_data, y_all_data = preprocess_data(test_data[0][1])\n",
    "\n",
    "for num in range(1,len(test_data)):    \n",
    "    X, y = preprocess_data(test_data[num][1])\n",
    "    X_all_data = np.concatenate((X_all_data, X), axis=0)\n",
    "    y_all_data = np.concatenate((y_all_data, y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all_data, y_all_data, test_size=0.33, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 2 0 1 2 1 0 0 2 2 2 0 0 1 2 1 2 2 2 2 2 3 0 1 2 2 0 2 1 1 1 2 2 1 2\n",
      " 0 2 2 1 3 3 2 1 2 3 0 3 2 2 2 0 2 3 2 0 1 0 2 1 1 3 3 1 2 0 3 2 1 2 2 3 2\n",
      " 1 2 1 2 2 2 2 2 2 0 2 2 1 3 0 1 0 1 2 0 2 2 2 3 1 3 3 0 1 2]\n",
      "[2 2 1 0 0 1 2 3 0 0 1 0 1 0 0 0 2 1 3 2 0 2 1 3 3 1 2 2 0 2 1 1 0 1 1 0 1\n",
      " 0 3 2 3 2 2 1 1 1 3 1 0 3 2 2 3 2 3 2 1 1 3 1 3 3 3 3 3 3 0 3 2 1 0 2 0 2\n",
      " 0 1 1 0 2 3 1 2 0 0 0 1 0 2 0 1 2 1 3 0 2 2 0 0 1 3 3 0 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5096153846153846"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(predictions)\n",
    "print(y_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten eine etwas bessere Accuracy von 0.5, welche aber immer noch ziemlich klein ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verwendung verschiedener Classifier\n",
    "Um zu sehen, ob der Accuracy-Score noch verbessert werden kann, werden verschiedene Classifier verwendet:\n",
    "\n",
    "- Decision Tree\n",
    "- k Nearest Neighbors\n",
    "- Linear SVM\n",
    "- Random Forest\n",
    "- Neural Net\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "0.5769230769230769\n",
      "\n",
      "k Nearest Neighbors\n",
      "0.6153846153846154\n",
      "\n",
      "Linear SVM\n",
      "0.40384615384615385\n",
      "\n",
      "Random Forest\n",
      "0.5384615384615384\n",
      "\n",
      "Neural Net\n",
      "0.5961538461538461\n",
      "\n",
      "Naive Bayes\n",
      "0.4423076923076923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [\"Decision Tree\", \"k Nearest Neighbors\", \"Linear SVM\", \n",
    "         \"Random Forest\", \"Neural Net\", \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    GaussianNB(),\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all_data, y_all_data, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "for index in range(0,len(classifiers)):\n",
    "    print(names[index])\n",
    "    clf = classifiers[index]\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(accuracy_score(predictions, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Der k-nearest-neighbors erzielt höhere Werte (höher als 0.6) als der Decision-Tree Klassifikator nach auch nach mehreren Ausführungen. \n",
    "- Der Neural net und random forest Klassifikator erzielt ähnliche Werte wie der Decision-Tree Klassifikator.\n",
    "- Der Naive Bayes und Linear SVM haben mit einem Wert von etwas 0.4 - 0.45 tiefer als der Decision-Tree Klassifikator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Schlussfolgerung\n",
    "Die Accuracy hat einen maximal Wert um 0.6, was noch nicht wünschenswert ist. \n",
    "\n",
    "Grund dafür kann sein, dass die Zeichnungen von den Symbolen in einer verschiedenen Strichstärke gemacht wurden und die Daten deshalb trotz gleichem Symbol sehr unterschiedlich sind. Um dem entgegen zu wirken, müssten für alle Datensätze die gleiche Stiftstärke verwendet werden. \n",
    "\n",
    "Ebenfalls kann durch eine grössere Sammlung an Trainingsdaten mehr Variationen abgedeckt und die Accuracy erhöht werden.\n",
    "Information der Daten reicht nicht aus für diese Methode.\n",
    "\n",
    "In einem weiteren Schritt könnten Bilder zuerst durch die Strichstärke in verschiedene Gruppen eingeteilt werden und je ein Klassifikator pro Strichstärke erstellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pva6",
   "language": "python",
   "name": "pva6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
